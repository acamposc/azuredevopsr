steps:
  - name: gcr.io/cloud-builders/gcloud
    args:
      - kms
      - decrypt
      - --ciphertext-file
      - /AZURE_PAT.txt.enc
      - --plaintext-file
      - /AZURE_PAT.txt
      - --location
      - us-central1
      - --keyring
      - attach-key-ring
      - --key
      - azure-devops-commits
    id: decrypt az_pat
  - name: gcr.io/cloud-builders/gcloud
    args:
      - kms
      - decrypt
      - --ciphertext-file
      - /GOOGLE_CLOUD_PROJECT_ID.txt.enc
      - --plaintext-file
      - /GOOGLE_CLOUD_PROJECT_ID.txt
      - --location
      - us-central1
      - --keyring
      - attach-key-ring
      - --key
      - azure-devops-commits
    id: decrypt gc_proj_id
  - name: gcr.io/cloud-builders/gcloud
    args:
      - kms
      - decrypt
      - --ciphertext-file
      - /attach-commits-fa50e59d273d.json.enc
      - --plaintext-file
      - /attach-commits-fa50e59d273d.json
      - --location
      - us-central1
      - --keyring
      - attach-key-ring
      - --key
      - azure-devops-commits
    id: decrypt gsa_path
  - name: gcr.io/cloud-builders/gcloud
    args:
      - kms
      - decrypt
      - --ciphertext-file
      - /GOOGLE_BIGQUERY_DATASET_NAME.TXT.enc
      - --plaintext-file
      - /GOOGLE_BIGQUERY_DATASET_NAME.TXT
      - --location
      - us-central1
      - --keyring
      - attach-key-ring
      - --key
      - azure-devops-commits
    id: decrypt dataset_name
  - name: gcr.io/cloud-builders/gcloud
    args:
      - kms
      - decrypt
      - --ciphertext-file
      - /GOOGLE_BIGQUERY_TABLE_NAME.txt.enc
      - --plaintext-file
      - /GOOGLE_BIGQUERY_TABLE_NAME.txt
      - --location
      - us-central1
      - --keyring
      - attach-key-ring
      - --key
      - azure-devops-commits
    id: decrypt table_name
  - name: rocker/r-base
    args:
      - Rscript
      - -e
      - "install.packages(\n  c(\"googleCloudStorageR\",\n    \"gargle\",\n    \"bigrquery\",\n
        \   \"tictoc\",\n    \"purrr\",\n    \"httr\",\n    \"jsonlite\",\n    \"dplyr\",\n
        \   \"RJSONIO\",\n    \"data.table\",\n    \"data.tree\",\n    \"devtools\"\n
        \   )\n) \n\n#library(devtools)\n#remotes::install_github(\"MarkEdmondson1234/googleCloudRunner\")\n\n#
        go"
  - name: rocker/r-base
    args:
      - Rscript
      - -e
      - "\n\nlibrary(tictoc)\ntic(\"step1\")\n#Dependencies\n\nlibrary(purrr)\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(RJSONIO)\nlibrary(data.table)\nlibrary(data.tree)\n\n\nsource('map_ks.r')\nsource('load.r')\n\n#Environment
        vars\naz_pat <<- AZURE_PAT$V1\n\n\n##########\n\norgs <- list(\n  org_mi_movistar
        = 'AtmMiMovistar',\n  #org_movistar_publica = 'AtmMovistar',\n  org_banco_falabella
        = 'AtmBancoFalabella',\n  org_esan= 'AtmESAN',\n  org_estilos = 'AtmEstilosPE',\n
        \ org_incarail = 'AtmIncaRail',\n  #org_mapfre_peru = 'AtmMapfre',\n  org_royal
        = 'AtmRoyal',\n  org_tls = 'AtmToulouse',\n  org_ucal = 'AtmUCAL',\n  org_attach
        = 'Attach'\n  \n)\n\n\n##########\n#https://adv-r.hadley.nz/functionals.html\n\n\n##########\n\n#
        List organization's projects\n# https://docs.microsoft.com/en-us/rest/api/azure/devops/core/projects/list?view=azure-devops-rest-5.1\n\n\n#Fetch
        all projects within organizations\nfn <- function(x){\n  if(!require(httr)){\n
        \   stop(\"httr not installed\")\n  } else {\n  \n  GET(\n    paste0(\n      \"https://dev.azure.com/\",\n
        \     x,\n      \"/_apis/projects?api-version=5.1\"\n    ),\n    authenticate(user
        = az_pat, password = az_pat)\n  )\n  }\n}\naz_dev_org_urls<-map(orgs, fn)\n\n#returned
        a list of responses\n#str(az_dev_org_urls)\n############\n\n\n\n############\n#
        Set up content names\norg_count <- 1:length(az_dev_org_urls)\nfn_names <-
        function(x,y){\n  if(!require(jsonlite)){\n    stop(\"jsonlite not installed\")\n
        \ } else {\n    projs <- rawToChar(az_dev_org_urls[x][[1]]$content)\n    projs_json
        <- jsonlite::fromJSON(projs)\n    projs_json_names <- projs_json$value$name\n
        \   \n  }}\nnms <- map(org_count, fn_names)\n\n\n############\n# List project
        names\norg_count <- length(nms)\n\nfn_repo_projs <- function(x){\n   nms[1:x]\n\n}\nrepo_projs_list
        <- map(org_count, fn_repo_projs)\n#repo_projs_list <- repo_projs_list[[1]]\n#repo_projs_list[[2]]\n\n\n############\n#Count
        projects from project list\n#It is really unnecessary, use \"org_count\" instead.\nfn_count_projs
        <- function(x){\n  length(repo_projs_list[[1]][[x]])\n}\ncount_projs <- map(1:org_count,
        fn_count_projs)\n#str(count_projs)\n\n############\n\n#Request all repo content.\n#GET
        https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=5.1\nfn_repos
        <- function(x, y){\n  if(!require(httr)){\n    stop('httr not installed')\n
        \ } else {\n    \n    GET(\n     paste0(\n        \"https://dev.azure.com/\",\n
        \       x,\n        \"/\",\n        y,\n        \"/_apis/git/repositories?api-version=5.1\"\n
        \     ),\n      authenticate(user = az_pat, password = az_pat)\n    )\n  }\n}\n\n#https://purrr.tidyverse.org/reference/map2.html\n#gsub()
        used to replace url whitespaces for the requests.\naz_dev_repos_urls <- map2(.x
        = rep(orgs, count_projs) , .y = gsub(\" \", \"%20\", unlist(repo_projs_list[[1]])),
        .f = fn_repos)\n\n#typeof(az_dev_repos_urls)\n#str(az_dev_repos_urls)\n\n\n############\n#extract
        repo id and request for the commits data\n\nlength_az_repos_urls <- 1:length(az_dev_repos_urls)\nextract_repo_id
        <- function(x){\n  if(!require(jsonlite)){\n    stop(\"jsonlite not installed\")\n
        \ } else {\n    body <- rawToChar(az_dev_repos_urls[x][[1]]$content)\n    body
        <- jsonlite::fromJSON(body)\n    body <- body$value$url\n    \n  } \n}\n\nproj_urls
        <- map(length_az_repos_urls, extract_repo_id)\n\n############\n\n# Retrieve
        commits and place them in memory.\n\nfn_retrieve_commits <- function(x){\n
        \ if(!require(httr)){\n    stop(\"httr not installed\")\n  } else {\n    GET(\n
        \     paste0(\n        proj_urls[x], \n        \"/commits\"\n      ),\n      authenticate(\n
        \       user = az_pat,\n        password = az_pat\n      )\n    )\n  }\n}\nretrieve_commits
        <- map(length_az_repos_urls, fn_retrieve_commits)\n\nfn_commits <- function(x){\n
        \ if(!require(jsonlite)){\n    stop(\"jsonlite not installed\")\n  } else
        {\n    commits <- rawToChar(retrieve_commits[x][[1]]$content)\n    commits
        <- jsonlite::fromJSON(commits)\n    commits \n  }\n}\ncommits <- map(length_az_repos_urls,
        fn_commits)\n#str(commits)\n\n\n\n# commits holds the values meant to be loaded
        in bigquery.\n############\n\n############\n#fn_commits_dataframe creates
        a list of dataframes\n\nfn_commits_dataframe <- function(x){\n  commits <-
        commits[[x]]$value\n\n}\ncommits_value <- map(length_az_repos_urls, fn_commits_dataframe)\n\n##############\n#
        select columns and bind rows in order to have one big tibble.\n# https://stackoverflow.com/questions/5234117/how-to-drop-columns-by-name-in-a-data-frame\n#
        https://stackoverflow.com/questions/15059285/row-binding-a-set-of-data-sets\n\ndesired_cols
        <- c(\"commitId\", \"author\", \"committer\", \"comment\", \"changeCounts\",
        \"url\", \"remoteUrl\")\nfn_select_cols <- function(x){\n  selected_cols <-
        commits_value[[x]][,desired_cols]\n}\ncommits_value <- map(length_az_repos_urls,fn_select_cols)\n\n\n#
        manipulate json\n# https://gist.github.com/gluc/5f780246d57897b57c6b\n\nfn_jsn_tbl
        <- function(x){\n  if(!require(data.tree)){\n    stop(\"data.tree not installed\")\n
        \ } else {\n    repos <- jsonlite::toJSON(commits_value)\n    repos <- jsonlite::fromJSON(repos,
        simplifyDataFrame = FALSE)\n    \n    repos <- as.Node(repos)\n    #print(repos,
        'commitId', 'date')\n\n    reposdf <- data.tree::ToDataFrameTable(x = repos,\n
        \                                          'commitId',\n                                           'email',\n
        \                                          'comment',\n                                           'Add',
        'Edit', 'Delete',\n                                           'url', 'remoteUrl',
        'date')\n    \n    # deduplicate, summarise rows and remove NAs.\n    # https://stackoverflow.com/questions/40820120/merging-two-rows-with-some-having-missing-values-in-r\n
        \   \n    if(!require(dplyr)){\n      stop('dplyr not installed')\n    } else
        {\n      \n      reposdf <<- \n        reposdf %>%\n        group_by(commitId,
        comment, url, remoteUrl) %>%\n        summarise(\n          email = max(email,
        na.rm = TRUE),\n          date = max(date, na.rm = TRUE),\n          Add =
        max(Add, na.rm = TRUE),\n          Edit = max(Edit, na.rm = TRUE),\n          Delete
        = max(Delete, na.rm = TRUE)\n        )\n    }\n    \n    #write.csv(reposdf,
        file = 'reposdf.csv')\n  }\n}\n#jsn_tbl <- map(length_az_repos_urls, fn_jsn_tbl)\nfn_jsn_tbl()\n\nfn_repos_org_proj
        <- function(){\n  if(!require(data.table)){\n    stop(\"data.table not installed\")\n
        \ } else {\n    remote_sep <- read.table(text = reposdf$remoteUrl, sep = \"/\",
        colClasses = \"character\")\n    az_org <- remote_sep$V4\n    az_proj <- remote_sep$V5\n
        \   \n    reposdf$org <- az_org\n    reposdf$proj <- az_proj\n    op <- options(digits.secs
        = 6)\n    reposdf$timestamp <- Sys.time()\n    \n    reposdf <<- reposdf\n
        \ }\n}\n\nfn_repos_org_proj()\n###########\n# upload data to bigquery\n# https://rdrr.io/cran/bigrquery/man/api-perform.html\n\n\n#
        bigquery fields\n\nfields <- \n  \n  list(\n    list(name = \"commitId\",
        type = \"string\",     description = \"Azure Repos commit id\"),\n    list(name
        = \"email\", type = \"string\",        description = \"Committer email\"),\n
        \   list(name = \"comment\", type = \"string\",      description = \"Comment\"),\n
        \   list(name = \"Add\", type = \"integer\",         description = \"Commiter
        adds\"),\n    list(name = \"Edit\", type = \"integer\",        description
        = \"Committer edits\"),\n    list(name = \"Delete\", type = \"integer\",      description
        = \"Committer deletes\"),\n    list(name = \"url\", type = \"string\",          description
        = \"Repo API url\"),\n    list(name = \"remoteUrl\", type = \"string\",    description
        = \"Remote url\"),\n    list(name = \"date\", type = \"timestamp\",      description
        = \"Declares when a change has been made\"),\n    list(name = \"org\", type
        = \"string\",          description = \"Azure Repos organization id\"),\n    list(name
        = \"proj\", type = \"string\",         description = \"Azure Repos project
        id within a organization\"),\n    list(name = \"timestamp\", type = \"timestamp\",
        \ description = \"Upload time, may be of use to max() this value to avoid
        duplicates\")\n    #list(name = \"commentTruncated\", type = \"string\"),\n
        \ )\n\n\n##############\n#create table, works like a charm.\n\nbq_proj_name
        <- gc_proj_id\nbq_dataset_name <- GOOGLE_BIGQUERY_DATASET_NAME$V1\nbq_tbl
        <- GOOGLE_BIGQUERY_TABLE_NAME$V1\nbq_table_name <- paste0(\n  bq_proj_name,\n
        \ \".\",\n  bq_dataset_name,\n  \".\",\n  bq_tbl\n)\n\n\n\n\nfn_bq_table_create
        <- function(x){\n  if(bq_table_exists(x)){\n    stop(\"bigquery table already
        exists\")\n  } else {\n  \n  bq_table_create(\n    x = x,\n    fields = as_bq_fields(fields)\n
        \ )\n}}\nfn_bq_table_create(bq_table_name)\n##############\n\n\nfn_bq_tbl_upload
        <- function(){\n  if(!require(bigrquery)){\n    stop(\"bigrquery not installed\")\n
        \ } else {\n    tb <- bq_table(\n      project = bq_proj_name,\n      dataset
        = bq_dataset_name,\n      table = bq_tbl\n    )\n    \n    dfr <- reposdf\n
        \   \n    bq_table_upload(tb, dfr)\n    \n  }\n  \n}\ntbl_upload <-  fn_bq_tbl_upload()\n\n##\n#
        next steps: review data in bigquery.\n\ntoc()"
